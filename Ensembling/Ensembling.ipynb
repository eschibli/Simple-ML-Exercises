{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC as SupportVectorClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling\n",
    "\n",
    "Here we will demonstrate how combining multiple classifiers can produce bette performance on unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data, seperate and binarize labels\n",
    "wine_data = pd.read_csv('data/wine_dataset.csv')\n",
    "wine_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like all of our variables are continuous. We make the target binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (wine_data['quality']/10).round()\n",
    "wine_data = wine_data.drop(\"quality\", axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some quick tests with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(wine_data, y, stratify=y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.637\n",
      "SVM Matthews' coefficient: 0.282\n",
      "RFC Accuracy: 0.637\n",
      "RFC Matthews' coefficient: 0.282\n",
      "QDA Accuracy: 0.747\n",
      "QDA Matthews' coefficient: 0.497\n",
      "LDA Accuracy: 0.769\n",
      "LDA Matthews' coefficient: 0.535\n"
     ]
    }
   ],
   "source": [
    "SVC = SupportVectorClassifier()\n",
    "SVC.fit(trainX, trainY)\n",
    "svm_acc = accuracy_score(testY, SVC.predict(testX))\n",
    "svm_matt_coef = matthews_corrcoef(testY, SVC.predict(testX))\n",
    "\n",
    "print(\"SVM Accuracy: {:0.3f}\".format(svm_acc))\n",
    "print(\"SVM Matthews' coefficient: {:0.3f}\".format(svm_matt_coef))\n",
    "\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(trainX, trainY)\n",
    "rfc_acc = accuracy_score(testY, RFC.predict(testX))\n",
    "rfc_matt_coef = matthews_corrcoef(testY, RFC.predict(testX))\n",
    "\n",
    "print(\"RFC Accuracy: {:0.3f}\".format(svm_acc))\n",
    "print(\"RFC Matthews' coefficient: {:0.3f}\".format(svm_matt_coef))\n",
    "\n",
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "QDA.fit(trainX, trainY)\n",
    "qda_acc = accuracy_score(testY, QDA.predict(testX))\n",
    "qda_matt_coef = matthews_corrcoef(testY, QDA.predict(testX))\n",
    "\n",
    "print(\"QDA Accuracy: {:0.3f}\".format(qda_acc))\n",
    "print(\"QDA Matthews' coefficient: {:0.3f}\".format(qda_matt_coef))\n",
    "\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA.fit(trainX, trainY)\n",
    "lda_acc = accuracy_score(testY, LDA.predict(testX))\n",
    "lda_matt_coef = matthews_corrcoef(testY, LDA.predict(testX))\n",
    "\n",
    "print(\"LDA Accuracy: {:0.3f}\".format(lda_acc))\n",
    "print(\"LDA Matthews' coefficient: {:0.3f}\".format(lda_matt_coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA performs the best, but the performance is not great.\n",
    "\n",
    "What happens if we let our classifiers vote?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembled Accuracy: 0.794\n",
      "Ensembled Matthews' coefficient: 0.585\n"
     ]
    }
   ],
   "source": [
    "predictions = np.vstack(( SVC.predict(testX),  RFC.predict(testX),  QDA.predict(testX),  LDA.predict(testX)))\n",
    "\n",
    "ens_predictions = np.round(np.mean(predictions, axis=0))\n",
    "ens_acc = accuracy_score(testY, ens_predictions)\n",
    "ens_matt_coef = matthews_corrcoef(testY, ens_predictions)\n",
    "\n",
    "print(\"Ensembled Accuracy: {:0.3f}\".format(ens_acc))\n",
    "print(\"Ensembled Matthews' coefficient: {:0.3f}\".format(ens_matt_coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are already doing slightly better! We expect that combining multiple classifiers will give us better results because their errors are likely tob e uncorrelated. \n",
    "\n",
    "We should be able to do even better if we combine classifiers with different hyperparameters and slightly different training sets. We will train many models with different hyperparameters on individual random samples of our training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC as SupportVectorClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
    "from sklearn.utils import resample\n",
    "\n",
    "class EnsembledClassifier:\n",
    "    \"\"\"\n",
    "    Voating ensembled of classifiers \n",
    "    \"\"\"\n",
    "    def __init__(self, acc_threshold=0.65, bootstrap_size = 1000, model_types=['svc', 'qda', 'rfc'], num_classifiers=25, Cs=[0.01, 0.1, 1, 10, 100], \n",
    "                 gammas=[0.01, 0.1, 1, 10, 100], kernels=['linear', 'rbf', 'sigmoid'], max_depths=[3, 4, 5, 6], \n",
    "                 max_trees=[25, 50, 100, 200], reg_params=[0, 0.001, 0.01, 0.1], linear=[True, False]):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        :param acc_threshold: (float) Minimum accuracy to keep a classifier\n",
    "        :param bootstrap size: (int) Number of training samples to select per classifier\n",
    "        :param num_classifiers: (int) Number of classifiers to train\n",
    "        :param model_types: (list) Types of models to train. Accepted values include 'qda', 'svc', and 'rfc'\n",
    "        :param gammas: (list) Values of gamma to use in SVMs. List of floats\n",
    "        :param kernels: (list) Kernals to use in SVMs. Accepted values include 'lienar', 'rbf', and 'sigmoid'\n",
    "        :param max_trees: (list) Values of max_trees to use in rfcs. \n",
    "        :param linear: (list) True is LDA, False is QDA. \n",
    "        \"\"\"\n",
    "    \n",
    "        self.acc_threshold, self.bootstrap_size, self.num_classifiers, self.Cs, self.gammas, self.kernels, self.max_depths, self.max_trees, self.reg_params, self.linear = acc_threshold, bootstrap_size, num_classifiers, Cs, gammas, kernels, max_depths, max_trees, reg_params, linear\n",
    "        \n",
    "        self.models = None\n",
    "        self.model_types = model_types\n",
    "        \n",
    "    def fit(self, X, y, verbose=True):\n",
    "        \"\"\"\n",
    "        Fit the classifiers\n",
    "        :param X: (Array-like) Training data\n",
    "        :param y: (Vector-like) Targets\n",
    "        :verbose: (bool) Print results to console\n",
    "        \"\"\"\n",
    "        self.models = []\n",
    "\n",
    "        for i in range(self.num_classifiers):\n",
    "            model_type = random.choice(self.model_types) # Randomly select a model\n",
    "            if model_type == 'svc':\n",
    "                params = {'C': random.choice(self.Cs), 'gamma': random.choice(self.gammas), \n",
    "                          'kernel': random.choice(self.kernels)}\n",
    "                model = SupportVectorClassifier(**params)\n",
    "            elif model_type == 'rfc':\n",
    "                params = {'max_depth': random.choice(self.max_depths), 'n_estimators': random.choice(self.max_trees)}\n",
    "                model = RandomForestClassifier(**params)\n",
    "            elif model_type == 'qda':\n",
    "                params = {'reg_param': random.choice(self.reg_params)}\n",
    "                if random.choice(self.linear):\n",
    "                    model = LinearDiscriminantAnalysis()\n",
    "                    params['linear'] = True\n",
    "                else:\n",
    "                    model = QuadraticDiscriminantAnalysis(**params)\n",
    "                    params['linear'] = False\n",
    "            \n",
    "            # Sample some data and fit the model\n",
    "            boots_x, boots_y = resample(X, y, n_samples=self.bootstrap_size)\n",
    "            boots_train_x, boots_test_x, boots_train_y, boots_test_y = train_test_split(boots_x, boots_y, stratify=boots_y, test_size=0.2)\n",
    "            model.fit(boots_train_x, boots_train_y)\n",
    "            acc = accuracy_score(boots_test_y, model.predict(boots_test_x))\n",
    "            \n",
    "            if verbose:\n",
    "                print('Model {} {} accuracy: {:0.3f}'.format(model_type, params, acc))\n",
    "\n",
    "            # Save the model if it's good\n",
    "            if acc > self.acc_threshold:\n",
    "                self.models.append( {'type': model_type, 'params': params, 'classifier': model, 'est_acc': acc})\n",
    "                \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions\n",
    "        :param X: (Array-like_ Feature vectors\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            try:\n",
    "                predictions.append(model['classifier'].predict_proba(testX)[:,1])\n",
    "            except:\n",
    "                predictions.append(model['classifier'].predict(testX))\n",
    "\n",
    "\n",
    "        predict_array = np.array(predictions)\n",
    "        ens_predictions = np.mean(predict_array, axis=0)\n",
    "        return ens_predictions\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        :param X: (Array-like_ Feature vectors\n",
    "        \"\"\"\n",
    "        return np.round(self.predict_proba(X))\n",
    "    \n",
    "    def get_classifiers(self):\n",
    "        \"\"\"\n",
    "        Get all trained classifiers\n",
    "        :returns: (list) List of trained classifiers\n",
    "        \"\"\"\n",
    "        classifiers = []\n",
    "        for model in self.models:\n",
    "            classifiers.append(model['classifier'])\n",
    "        return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model rfc {'max_depth': 6, 'n_estimators': 25} accuracy: 0.838\n",
      "Model qda {'reg_param': 0.001, 'linear': False} accuracy: 0.762\n",
      "Model svc {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'} accuracy: 0.512\n",
      "Model qda {'reg_param': 0.1, 'linear': True} accuracy: 0.713\n",
      "Model qda {'reg_param': 0.001, 'linear': True} accuracy: 0.725\n",
      "Model svc {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'} accuracy: 0.531\n",
      "Model qda {'reg_param': 0.1, 'linear': False} accuracy: 0.725\n",
      "Model qda {'reg_param': 0.01, 'linear': False} accuracy: 0.756\n",
      "Model svc {'C': 100, 'gamma': 0.1, 'kernel': 'sigmoid'} accuracy: 0.544\n",
      "Model qda {'reg_param': 0.01, 'linear': False} accuracy: 0.725\n",
      "Model rfc {'max_depth': 6, 'n_estimators': 100} accuracy: 0.756\n",
      "Model rfc {'max_depth': 5, 'n_estimators': 50} accuracy: 0.781\n",
      "Model svc {'C': 0.01, 'gamma': 100, 'kernel': 'linear'} accuracy: 0.706\n",
      "Model rfc {'max_depth': 4, 'n_estimators': 100} accuracy: 0.769\n",
      "Model qda {'reg_param': 0.1, 'linear': False} accuracy: 0.662\n",
      "Model svc {'C': 0.01, 'gamma': 0.1, 'kernel': 'linear'} accuracy: 0.669\n",
      "Model rfc {'max_depth': 5, 'n_estimators': 50} accuracy: 0.769\n",
      "Model rfc {'max_depth': 5, 'n_estimators': 100} accuracy: 0.800\n",
      "Model qda {'reg_param': 0, 'linear': True} accuracy: 0.706\n",
      "Model rfc {'max_depth': 5, 'n_estimators': 200} accuracy: 0.750\n",
      "Model rfc {'max_depth': 6, 'n_estimators': 200} accuracy: 0.831\n",
      "Model rfc {'max_depth': 3, 'n_estimators': 100} accuracy: 0.787\n",
      "Model rfc {'max_depth': 4, 'n_estimators': 100} accuracy: 0.750\n",
      "Model qda {'reg_param': 0.1, 'linear': True} accuracy: 0.719\n",
      "Model rfc {'max_depth': 5, 'n_estimators': 200} accuracy: 0.812\n"
     ]
    }
   ],
   "source": [
    "EC = EnsembledClassifier(bootstrap_size=800, acc_threshold=0.7)\n",
    "EC.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembled Accuracy: 0.775\n",
      "Ensembled Matthews' coefficient: 0.547\n"
     ]
    }
   ],
   "source": [
    "ens_predictions = EC.predict(testX)\n",
    "ens_acc = accuracy_score(testY, ens_predictions)\n",
    "ens_matt_coef = matthews_corrcoef(testY, ens_predictions)\n",
    "\n",
    "print(\"Ensembled Accuracy: {:0.3f}\".format(ens_acc))\n",
    "print(\"Ensembled Matthews' coefficient: {:0.3f}\".format(ens_matt_coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better! We can also fit a classifier on the outputs from our original classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class L2_Classifier:\n",
    "    \"\"\"\n",
    "    Heirarchical classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, L1_classifiers, Classifier=LogisticRegression, **kwargs):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        :param L1_classifiers: (list) A list of (trained) classifiers\n",
    "        \"\"\"\n",
    "        self.L1_classifiers = L1_classifiers\n",
    "        self.L2_Classifier = Classifier(**kwargs)\n",
    "        \n",
    "    def get_predictions(self, X):\n",
    "        \"\"\"\n",
    "        Get a list of predictions from our models\n",
    "        :param X: Features vectors\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for model in self.L1_classifiers:\n",
    "            try: \n",
    "                output = model.predict_proba(X)[:,1]\n",
    "            except:\n",
    "                output = model.predict(X)\n",
    "                \n",
    "            predictions.append(output)\n",
    "        return predictions\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit (only our level two classifier)\n",
    "        :param X: (Array-like) Training data\n",
    "        :param y: (Vector-like) Targets\n",
    "        \"\"\"\n",
    "        L1_predictions = self.get_predictions(X)\n",
    "        X1 = np.array(L1_predictions).T\n",
    "        self.L2_Classifier.fit(X1, y)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Make binary predictions\n",
    "        :param X: (Array-like_ Feature vectors\n",
    "        \"\"\"\n",
    "        L1_predictions = self.get_predictions(X)\n",
    "        X1 = np.array(L1_predictions).T\n",
    "        L2_predictions = self.L2_Classifier.predict_proba(X1)[:,1]\n",
    "        return L2_predictions\n",
    "    \n",
    "    def predict(self, X):\n",
    "        L2_predictions = self.predict_proba(X)\n",
    "        return np.round(L2_predictions)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2 = L2_Classifier(EC.get_classifiers())\n",
    "L2.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-level Accuracy: 0.781\n",
      "Two-level Matthews coefficient: 0.560\n"
     ]
    }
   ],
   "source": [
    "l2_predictions = L2.predict(testX)\n",
    "l2_acc = accuracy_score(testY, l2_predictions)\n",
    "l2_matt_coef = matthews_corrcoef(testY, l2_predictions)\n",
    "\n",
    "print(\"Two-level Accuracy: {:0.3f}\".format(l2_acc))\n",
    "print(\"Two-level Matthews coefficient: {:0.3f}\".format(l2_matt_coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
